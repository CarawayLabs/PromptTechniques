# PromptTechniques
Demonstrating the use of different LLM Prompt Techniques that are available. I'll be leveraging Python and Semantic Kernel to produce this. 

This repo is intended to give a limited introduction to prompting of Large Language Models. These are some of the topics that we will cover:
- Best Practices
- Roles
- Formatting Output
- Summarization
- Inference
- Various Prompt Techniques or Prompt Theories

This work will be demonstrated using Python to orchestrate the LLM Calls, but the information shared is agnostic of Python. These lessons about prompting apply for API Access to LLMs and also when accessing LLMs via their GUI. 

Due to overwhelming familiarity, this lesson will be focused on ChatGPT. 

Included in this repo is a library of resources and additional learning that I pulled from when compiling this training. Please see the resources file for further details. 

Happy Prompting! :)